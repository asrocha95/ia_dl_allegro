%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Lauro Cesar Araujo at 2015-04-27 19:43:45 -0300 


%% Saved with string encoding Unicode (UTF-8) 

@misc{vanhasselt2015deep,
      title={Deep Reinforcement Learning with Double Q-learning}, 
      author={Hado van Hasselt and Arthur Guez and David Silver},
      year={2015},
      eprint={1509.06461},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{ThomasAndrew:adv_ml,
author={Andrew Thomas},
year={2020},
url="https://adventuresinmachinelearning.com/double-q-reinforcement-learning-in-tensorflow-2/",
Urlaccessdate = {17 out 2020}
}

@inproceedings{Lin1992ReinforcementLF,
  title={Reinforcement learning for robots using neural networks},
  author={L. Lin},
  year={1992}
}

@misc{brockman2016openai,
      title={OpenAI Gym}, 
      author={Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
      year={2016},
      eprint={1606.01540},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Watkins-Dayan-Qlearning,
author = {Watkins, Christopher and Dayan, Peter},
year = {1992},
month = {05},
pages = {279-292},
title = {Technical Note: Q-Learning},
volume = {8},
journal = {Machine Learning},
doi = {10.1007/BF00992698}
}

@book{sutton-barto-rl-intro,
 author = {Sutton, Richard and Barto, Andrew},
 title = {Reinforcement Learning: An Introduction},
 year = {1998},
 publisher = {MIT Press},
} 

@article{play-atari-drl-deepmind,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  archivePrefix = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{arcade-learning-enviroment,
  author    = {Marc G. Bellemare and
               Yavar Naddaf and
               Joel Veness and
               Michael Bowling},
  title     = {The Arcade Learning Environment: An Evaluation Platform for General
               Agents},
  journal   = {CoRR},
  volume    = {abs/1207.4708},
  year      = {2012},
  url       = {http://arxiv.org/abs/1207.4708},
  archivePrefix = {arXiv},
  eprint    = {1207.4708},
  timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1207-4708},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{dl-IoT, 
author={J. {Tang} and D. {Sun} and S. {Liu} and J. {Gaudiot}}, 
journal={Computer}, 
title={Enabling Deep Learning on IoT Devices}, 
year={2017}, 
volume={50}, 
number={10}, 
pages={92-96}, 
keywords={Internet of Things;learning (artificial intelligence);deep learning;Internet of Things devices;unstructured multimedia data;low-power IoT products;Internet of Things;Machine learning;Low power electronics;Performance evaluation;Cloud computing;deep learning;IoT;Internet of Things;machine learning;cloud computing;embedded devices;The IoT Connection}, 
doi={10.1109/MC.2017.3641648}, 
ISSN={}, 
month={},}

@article {Gebru13108,
	author = {Gebru, Timnit and Krause, Jonathan and Wang, Yilun and Chen, Duyun and Deng, Jia and Aiden, Erez Lieberman and Fei-Fei, Li},
	title = {Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States},
	volume = {114},
	number = {50},
	pages = {13108--13113},
	year = {2017},
	doi = {10.1073/pnas.1700035114},
	publisher = {National Academy of Sciences},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/114/50/13108},
	eprint = {https://www.pnas.org/content/114/50/13108.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}



@article{doi:10.1175/JHM-D-15-0075.1,
author = {Tao, Yumeng and Gao, Xiaogang and Hsu, Kuolin and Sorooshian, Soroosh and Ihler, Alexander},
title = {A Deep Neural Network Modeling Framework to Reduce Bias in Satellite Precipitation Products},
journal = {Journal of Hydrometeorology},
volume = {17},
number = {3},
pages = {931-945},
year = {2016},
doi = {10.1175/JHM-D-15-0075.1},

URL = { 
        https://doi.org/10.1175/JHM-D-15-0075.1
    
},
eprint = { 
        https://doi.org/10.1175/JHM-D-15-0075.1
    
}
}


@article{Debidatta:playing-games-drl:2016,
author={Debidatta Dwibedi and Anirudh Vemula},
year={2016},
url="https://pdfs.semanticscholar.org/179d/04d9da112c16b6fa5310c273d66de65e5768.pdf",
Urlaccessdate = {18 ago 2019}
}

@inproceedings{Ripamonti:Believable-group-behaviours:2017, 
author={L. A. {Ripamonti} and S. {Gratani} and D. {Maggiorini} and D. {Gadia} and A. {Bujari}}, 
booktitle={2017 IEEE Symposium on Computers and Communications (ISCC)}, 
title={Believable group behaviours for NPCs in FPS games}, 
year={2017}, 
volume={}, 
number={}, 
pages={12-17}, 
keywords={behavioural sciences;computer games;decision making;entertainment;middleware;video games;entertainment;believable group behaviours;nonplaying characters;first-person-shooter games;decision making;publisher-subscribers communication pattern;NPC;Artificial Intelligence;video game;group behaviour;agents;First Person Shooter games (FPSs);game design}, 
doi={10.1109/ISCC.2017.8024497}, 
ISSN={}, 
month={July},}

@inproceedings{Guerrero:AI-Game-Design:2018, 
author={C. {Guerrero-Romero} and S. M. {Lucas} and D. {Perez-Liebana}}, 
booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)}, 
title={Using a Team of General AI Algorithms to Assist Game Design and Testing}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-8}, 
keywords={automatic testing;computer games;multi-agent systems;program debugging;influence design;testing processes;bug fixing;general video game playing;general AI algorithms;assist game design;artificial general intelligence agents;GVGP;differentiated goals;visual information;logging system;detect anomalies;Games;Artificial intelligence;Automatic testing;Planning;Evolutionary computation;Collaboration;methodology;General Artificial Intelligence;automatic testing;game design;team of agents}, 
doi={10.1109/CIG.2018.8490417}, 
ISSN={}, 
month={Aug},}

@article{Ripamonti2017,
author="Ripamonti, Laura Anna
and Mannal{\`a}, Mattia
and Gadia, Davide
and Maggiorini, Dario",
title="Procedural content generation for platformers: designing and testing FUN PLEdGE",
journal="Multimedia Tools and Applications",
year="2017",
month="Feb",
day="01",
volume="76",
number="4",
pages="5001--5050",
abstract="Video games are a peculiar medium, standing at the crossing point between art and software application, and characterized by an active involvement of its audience. The complexity of the product generates a huge challenge for the companies that develop video games. In the development process, level designers play a crucial role: they are in charge of declining the theoretical framework developed by the game designer into game levels, which contain the actual gameplay scenarios. Hence, the final goal of any level designer is to valorize the game design by creating enjoyable gaming experiences while, at the same time, respecting several constraints. To lighten the burden on level designers, several semi-automated approaches to level generation have appeared in time, but the majority of these tools suffer from several drawbacks. In the present work, we tackle the issue of designing, prototyping and testing FUN PLEdGE, a general-purpose automated levels generator and editor for platform video games. Its main goal is to shrink development time while producing -- unassisted -- levels that are both playable and fun. Moreover, our tool provides the maximum freedom to the level designer, by avoiding to impose unnecessary constraints on the structure of the levels and by guaranteeing the possibility to modify and personalize by hand the generated levels. During this process, the generator assists the designer by suggesting corrections functional to the quality of the player experience. To prove the effectiveness of our prototypal application we have also developed and tested with players a platform game. In the same vein, we asked to a group of game developers to test FUN PLEdGE.",
issn="1573-7721",
doi="10.1007/s11042-016-3636-3",
url="https://doi.org/10.1007/s11042-016-3636-3"
}



@inproceedings{Karavolos:automated-level-design:2018, 
author={D. {Karavolos} and A. {Liapis} and G. N. {Yannakakis}}, 
booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)}, 
title={Using a Surrogate Model of Gameplay for Automated Level Design}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={This paper describes how a surrogate model of the interrelations between different types of content in the same game can be used for level generation. Specifically, the model associates level structure and game rules with gameplay outcomes in a shooter game. We use a deep learning approach to train a model on simulated playthroughs of two-player deathmatch games, in diverse levels and with different character classes per player. Findings in this paper show that the model can predict the duration and winner of the match given a top-down map of the level and the parameters of the two players' character classes. With this surrogate model in place, we investigate which level structures would result in a balanced match of short, medium or long duration for a given set of character classes. Using evolutionary computation, we are able to discover levels which improve the balance between different classes. This opens up potential applications for a designer tool which can adapt a human authored map to fit the designer's desired gameplay outcomes, taking account of the game's rules.}, 
keywords={computer games;evolutionary computation;learning (artificial intelligence);trees (mathematics);model associates level;gameplay outcomes;shooter game;deep learning approach;two-player deathmatch games;diverse levels;surrogate model;level structures;automated level design;game rules;top-down map;two players character classes;evolutionary computation;Games;Computational modeling;Adaptation models;Machine learning;Weapons;Tools;Generators;deep learning;surrogate model;artificial evolution;procedural content generation;computational creativity}, 
doi={10.1109/CIG.2018.8490425}, 
ISSN={}, 
month={Aug},}

@inproceedings{Piergigli:drl:2019, 
author={D. {Piergigli} and L. A. {Ripamonti} and D. {Maggiorini} and D. {Gadia}}, 
booktitle={2019 IEEE Conference on Games (CoG)}, 
title={Deep Reinforcement Learning to train agents in a multiplayer First Person Shooter: some preliminary results}, 
year={2019}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Training agents to play in contemporary multiplayer actions game is a challenging task, especially when agents are expected to cooperate in a hostile environment while performing several different actions at the same time. Nonetheless, this topic is assuming a growing importance due to the rampaging diffusion of this game genre and its related e-sports. Agents playing in a multiplayer survival first person shooter game should mimic a human player, hence they should learn how to: survive in unexplored environment, improve their combat skills, deal with unexpected events, coordinate with allies and reach a good ranking among the players community. Our aim has been to design, develop and test a preliminary solution that exploits Proximal Policy Optimization algorithms to train agents without the need of a human expert, with the final goal of creating teams composed only by artificial players.}, 
keywords={computer games;learning (artificial intelligence);optimisation;hostile environment;rampaging diffusion;game genre;multiplayer survival first person shooter game;human player;players community;e-sports;deep reinforcement learning;proximal policy optimization algorithms;multiplayer actions game;combat skills;artificial players;machine learning;neural network;deep reinforcement learning;e-sports;video games;shooter games;artificial intelligence;first person shooter game;artificial player}, 
doi={10.1109/CIG.2019.8848061}, 
ISSN={}, 
month={Aug},}

@book{Millington:2009:AIG:1795711,
 author = {Millington, Ian and Funge, John},
 title = {Artificial Intelligence for Games, Second Edition},
 year = {2009},
 isbn = {0123747317, 9780123747310},
 edition = {2nd},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{Yannakakis:2012:GAR:2212908.2212954,
 author = {Yannakakis, Geogios N.},
 title = {Game AI Revisited},
 booktitle = {Proceedings of the 9th Conference on Computing Frontiers},
 series = {CF '12},
 year = {2012},
 isbn = {978-1-4503-1215-8},
 location = {Cagliari, Italy},
 pages = {285--292},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2212908.2212954},
 doi = {10.1145/2212908.2212954},
 acmid = {2212954},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {game AI flagships, game artificial intelligence, game data mining, player experience modeling, procedural content generation},
}

@article{Botvinick:rl-fastandslow:2019,
	Abstract = {Deep reinforcement learning (RL) methods have driven impressive advances in artificial intelligence in recent years, exceeding human performance in domains ranging from Atari to Go to no-limit poker. This progress has drawn the attention of cognitive scientists interested in understanding human learning. However, the concern has been raised that deep RL may be too sample-inefficient ? that is, it may simply be too slow ? to provide a plausible model of how humans learn. In the present review, we counter this critique by describing recently developed techniques that allow deep RL to operate more nimbly, solving problems much more quickly than previous methods. Although these techniques were developed in an AI context, we propose that they may have rich implications for psychology and neuroscience. A key insight, arising from these AI methods, concerns the fundamental connection between fast RL and slower, more incremental forms of learning.},
	Annote = {doi: 10.1016/j.tics.2019.02.006},
	Author = {Botvinick, Matthew and Ritter, Sam and Wang, Jane X. and Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis},
	Booktitle = {Trends in Cognitive Sciences},
	Date = {2019/05/01},
	Date-Added = {2019-10-18 01:44:27 -0300},
	Date-Modified = {2019-10-18 01:45:18 -0300},
	Doi = {10.1016/j.tics.2019.02.006},
	Isbn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	M3 = {doi: 10.1016/j.tics.2019.02.006},
	Month = {2019/10/17},
	N2 = {Deep reinforcement learning (RL) methods have driven impressive advances in artificial intelligence in recent years, exceeding human performance in domains ranging from Atari to Go to no-limit poker. This progress has drawn the attention of cognitive scientists interested in understanding human learning. However, the concern has been raised that deep RL may be too sample-inefficient ? that is, it may simply be too slow ? to provide a plausible model of how humans learn. In the present review, we counter this critique by describing recently developed techniques that allow deep RL to operate more nimbly, solving problems much more quickly than previous methods. Although these techniques were developed in an AI context, we propose that they may have rich implications for psychology and neuroscience. A key insight, arising from these AI methods, concerns the fundamental connection between fast RL and slower, more incremental forms of learning.},
	Number = {5},
	Pages = {408--422},
	Publisher = {Elsevier},
	Title = {Reinforcement Learning, Fast and Slow},
	Ty = {JOUR},
	Url = {https://doi.org/10.1016/j.tics.2019.02.006},
	Volume = {23},
	Year = {2019},
	Year1 = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.tics.2019.02.006}}


@article{Yeung:comp-vis:2019,
	Abstract = {Early and frequent patient mobilization substantially mitigates risk for post-intensive care syndrome and long-term functional impairment. We developed and tested computer vision algorithms to detect patient mobilization activities occurring in an adult ICU. Mobility activities were defined as moving the patient into and out of bed, and moving the patient into and out of a chair. A data set of privacy-safe-depth-video images was collected in the Intermountain LDS Hospital ICU, comprising 563 instances of mobility activities and 98,801 total frames of video data from seven wall-mounted depth sensors. In all, 67{\%} of the mobility activity instances were used to train algorithms to detect mobility activity occurrence and duration, and the number of healthcare personnel involved in each activity. The remaining 33{\%} of the mobility instances were used for algorithm evaluation. The algorithm for detecting mobility activities attained a mean specificity of 89.2{\%} and sensitivity of 87.2{\%} over the four activities; the algorithm for quantifying the number of personnel involved attained a mean accuracy of 68.8{\%}.},
	Author = {Yeung, Serena and Rinaldo, Francesca and Jopling, Jeffrey and Liu, Bingbin and Mehra, Rishab and Downing, N. Lance and Guo, Michelle and Bianconi, Gabriel M. and Alahi, Alexandre and Lee, Julia and Campbell, Brandi and Deru, Kayla and Beninati, William and Fei-Fei, Li and Milstein, Arnold},
	Da = {2019/03/01},
	Date-Added = {2019-10-18 01:21:55 -0300},
	Date-Modified = {2019-10-18 01:23:11 -0300},
	Doi = {10.1038/s41746-019-0087-z},
	Id = {Yeung2019},
	Isbn = {2398-6352},
	Journal = {npj Digital Medicine},
	Number = {1},
	Pages = {11},
	Title = {A computer vision system for deep learning-based detection of patient mobilization activities in the ICU},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41746-019-0087-z},
	Volume = {2},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41746-019-0087-z}}


@article{Young_2018,
   title={Recent Trends in Deep Learning Based Natural Language Processing [Review Article]},
   volume={13},
   ISSN={1556-6048},
   url={http://dx.doi.org/10.1109/mci.2018.2840738},
   DOI={10.1109/mci.2018.2840738},
   number={3},
   journal={IEEE Computational Intelligence Magazine},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Young, Tom and Hazarika, Devamanyu and Poria, Soujanya and Cambria, Erik},
   year={2018},
   month={Aug},
   pages={55–75}
}

@article{nassif:speech-rec:2019, 
author={A. B. {Nassif} and I. {Shahin} and I. {Attili} and M. {Azzeh} and K. {Shaalan}}, 
journal={IEEE Access}, 
title={Speech Recognition Using Deep Neural Networks: A Systematic Review}, 
year={2019}, 
volume={7}, 
number={}, 
pages={19143-19165}, 
abstract={Over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. However, in the past few years, research has focused on utilizing deep learning for speech-related applications. This new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. This paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. The results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics.}, 
keywords={learning (artificial intelligence);neural nets;speech processing;speech recognition;statistical analysis;deep learning;machine learning;speech applications;speech recognition;deep neural networks;systematic review;speech processing applications;speech-related applications;attractive area;Hidden Markov models;Speech recognition;Neural networks;Deep learning;Feature extraction;Computer architecture;Acoustics;Speech recognition;deep neural network;systematic review}, 
doi={10.1109/ACCESS.2019.2896880}, 
ISSN={}, 
month={},}

@misc{allegro,
	Author = {Shawn Hargreaves},
	Title = {Allegro},
	Url = {https://liballeg.org/index.html},
	Urlaccessdate = {8 out 2019},
	Year = {1990},
}

@misc{pln-o-que-e,
	Author = {Jéssica Rodrigues},
	Title = {O que é o Processamento de Linguagem Natural?},
	Url = {https://medium.com/botsbrasil/o-que-é-o-processamento-de-linguagem-natural-49ece9371cff},
	Urlaccessdate = {2 set 2019},
	Year = {2017},
}


@article{social-juristic-challenges-ai,
	Abstract = {Artificial intelligence is becoming seamlessly integrated into our everyday lives, augmenting our knowledge and capabilities in driving, avoiding traffic, finding friends, choosing the perfect movie, and even cooking a healthier meal. It also has a significant impact on many aspects of society and industry, ranging from scientific discovery, healthcare and medical diagnostics to smart cities, transport and sustainability. Within this 21st century `man meets machine'reality unfolding, several social and juristic challenges emerge for which we are poorly prepared. We here review social dilemmas where individual interests are at odds with the interests of others, and where artificial intelligence might have a particularly hard time making the right decision. An example thereof is the well-known social dilemma of autonomous vehicles. We also review juristic challenges, with a focus on torts that are at least partly or seemingly due to artificial intelligence, resulting in the claimant suffering a loss or harm. Here the challenge is to determine who is legally liable, and to what extent. We conclude with an outlook and with a short set of guidelines for constructively mitigating described challenges.},
	Author = {Perc, Matja{\v z} and Ozer, Mahmut and Hojnik, Janja},
	Da = {2019/06/25},
	Date-Added = {2019-12-04 10:52:35 -0300},
	Date-Modified = {2019-12-04 10:59:25 -0300},
	Doi = {10.1057/s41599-019-0278-x},
	Id = {Perc2019},
	Isbn = {2055-1045},
	Journal = {Palgrave Communications},
	Number = {1},
	Pages = {61},
	Title = {Social and juristic challenges of artificial intelligence},
	Ty = {JOUR},
	Url = {https://doi.org/10.1057/s41599-019-0278-x},
	Volume = {5},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1057/s41599-019-0278-x}}



@article{robu-valentin-flyn:ethical-social-challenges-ai,
	Abstract = {Artificial intelligence and machine learning are increasingly seen as key technologies for building more decentralized and resilient energy grids. However, researchers must consider the ethical and social implications of these developments.},
	Author = {Robu, Valentin and Flynn, David and Andoni, Merlinda and Mokhtar, Maizura},
	Da = {2019/11/25},
	Date-Added = {2019-12-04 11:04:41 -0300},
	Date-Modified = {2019-12-04 11:05:55 -0300},
	Doi = {10.1038/s42256-019-0120-6},
	Id = {Robu2019},
	Isbn = {2522-5839},
	Journal = {Nature Machine Intelligence},
	Title = {Consider ethical and social challenges in smart grid research},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s42256-019-0120-6},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1038/s42256-019-0120-6}}

	
@article{vinyals:gm-lv-starcraft,
	Abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1--3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8{\%} of officially ranked human players.},
	Author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, R{\'e}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"u}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
	Da = {2019/11/01},
	Date-Added = {2019-12-04 23:16:41 -0300},
	Date-Modified = {2019-12-04 23:17:16 -0300},
	Doi = {10.1038/s41586-019-1724-z},
	Id = {Vinyals2019},
	Isbn = {1476-4687},
	Journal = {Nature},
	Number = {7782},
	Pages = {350--354},
	Title = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41586-019-1724-z},
	Volume = {575},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41586-019-1724-z}}



@misc{beg-guide-rl,
	Author = {Chris Nicholson},
	Title = {A Beginner's Guide to Deep Reinforcement Learning},
	Url = {https://skymind.ai/wiki/deep-reinforcement-learning},
	Urlaccessdate = {8 out 2019},
	Year={2016}
}

@misc{comi:teach:AI:DRL:2018,
	Author = {Mauro Comi},
	Title = {How to teach AI to play Games: Deep Reinforcement Learning},
	Url = {https://towardsdatascience.com/how-to-teach-an-ai-to-play-games-deep-reinforcement-learning-28f9b920440a},
	Urlaccessdate = {8 out 2019},
	Year={2018},
	month = {11},
}

@misc{Marr:AI-Danger,
	Author = {Bernard Marr},
	Title = {Is Artificial Intelligence Dangerous? 6 AI Risks Everyone Should Know About},
	Url = {https://www.forbes.com/sites/bernardmarr/2018/11/19/is-artificial-intelligence-dangerous-6-ai-risks-everyone-should-know-about/#256480952404},
	Urlaccessdate = {11 nov 2019},
	Year={2018},
	month = {11},
}

@book{reinforcement-learning-intro-2018,
    title={Reinforcement Learning: An Introduction},
    author={Richard S. Sutton and Andrew G. Barto},
    Edition = {2},
    publisher={MIT Press},
    note={\url{http://incompleteideas.net/book/the-book.html}},
    year={2018}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@manual{deep-learning-book-br,
	Title = {Deep Learning Book},
	Organization = {Data Science Academy},
	Year = {2019},
	Url = {http://www.deeplearningbook.com.br/},
	Urlaccessdate = {2 ago 2019}
	}

@book{menabrea1843sketch,
	title={Sketch of the Analytical Engine invented by Charles Babbage ... with notes by the translator. Extracted from the 'Scientific Memoirs,' etc. [The translator's notes signed: A.L.L. ie. Augusta Ada King, Countess Lovelace.]},
	author={MENABREA, L.F. and Babbage, C. and Lovelace, A.K.C. and L, A.A.},
	url={https://books.google.com.br/books?id=hPRmnQEACAAJ},
	year={1843},
	publisher={R. \& J. E. Taylor}
}

@book{Hsu:2002:BDB:601291,
	author = {Hsu, Feng-Hsiung},
	title = {Behind Deep Blue: Building the Computer That Defeated the World Chess Champion},
	year = {2002},
	isbn = {0691090653},
	publisher = {Princeton University Press},
	address = {Princeton, NJ, USA},
}


@article{mnih-human-control-drl,
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	Date = {2015/02/25/online},
	Date-Added = {2019-10-02 22:05:58 +0000},
	Date-Modified = {2019-10-02 22:05:58 +0000},
	Day = {25},
	Journal = {Nature},
	L3 = {10.1038/nature14236; https://www.nature.com/articles/nature14236#supplementary-information},
	Month = {02},
	Pages = {529 EP  -},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved. SN  -},
	Title = {Human-level control through deep reinforcement learning},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/nature14236},
	Urlaccessdate = {2 ago 2019},
	Volume = {518},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1038/nature14236}
}

@article{dicarlo-afrax-yamins:2014,
Author = {Arash Afraz, Daniel L.K. Yamins, James J. DiCarlo},
Journal = {Cold Spring Harb Symp Quant},
Publisher = {Cold Spring Harbor Laboratory Press; all rights reserved},
Title = {Neural Mechanisms Underlying Visual Object Recognition},
Url = {https://doi.org/10.1101/sqb.2014.79.024729},
Urlaccessdate = {2 ago 2019},
Year = {2014},
Bdsk-Url-1 = {https://doi.org/10.1101/sqb.2014.79.024729}}


@article{silva:amb-jd-allegro,
address = {Departmento de Ciência da Computação (DCC) da Universidade Federal de Minas Gerais (UFMG), Belo horizonte, Brasil},
Author = {Arthur Phillip Silva},
Title = {Ambiente para Desenvolvimento de Inteligência Artificial em Jogos Allegro},
Url = {https://github.com/artphil/allegro_game_ai},
Urlaccessdate = {8 out 2019},
Year = {2019}}

@inproceedings{deep-learning-games,
	title	= {Deep Learning Games},
	author	= {Dale Schuurmans, Martin Zinkevich},
	year	= {2016},
	URL	= {https://papers.nips.cc/paper/6315-deep-learning-games.pdf},
	Urlaccessdate = {2 ago 2019}
}

@misc{dahl2014multitask,
    title={Multi-task Neural Networks for QSAR Predictions},
    author={George E. Dahl and Navdeep Jaitly and Ruslan Salakhutdinov},
    year={2014},
    eprint={1406.1231},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}


@article{baldi:s:w:2015,
	Abstract = {Collisions at high-energy particle colliders are a traditionally fruitful source of exotic particle discoveries. Finding these rare particles requires solving difficult signal-versus-background classification problems, hence machine-learning approaches are often used. Standard approaches have relied on `shallow'machine-learning models that have a limited capacity to learn complex nonlinear functions of the inputs, and rely on a painstaking search through manually constructed nonlinear features. Progress on this problem has slowed, as a variety of techniques have shown equivalent performance. Recent advances in the field of deep learning make it possible to learn more complex functions and better discriminate between signal and background classes. Here, using benchmark data sets, we show that deep-learning methods need no manually constructed inputs and yet improve the classification metric by as much as 8{\%} over the best current approaches. This demonstrates that deep-learning approaches can improve the power of collider searches for exotic particles.},
	Author = {Baldi, P. and Sadowski, P. and Whiteson, D.},
	Da = {2014/07/02},
	Date-Added = {2019-10-02 20:22:45 -0300},
	Date-Modified = {2019-10-02 20:24:29 -0300},
	Doi = {10.1038/ncomms5308},
	Id = {Baldi2014},
	Isbn = {2041-1723},
	Journal = {Nature Communications},
	Number = {1},
	Pages = {4308},
	Title = {Searching for exotic particles in high-energy physics with deep learning},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/ncomms5308},
	Volume = {5},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1038/ncomms5308}}
