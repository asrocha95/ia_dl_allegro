
TY  - JOUR
T1  - Reinforcement Learning, Fast and Slow
AU  - Botvinick, Matthew
AU  - Ritter, Sam
AU  - Wang, Jane X.
AU  - Kurth-Nelson, Zeb
AU  - Blundell, Charles
AU  - Hassabis, Demis
Y1  - 2019/05/01
PY  - 2019
N1  - doi: 10.1016/j.tics.2019.02.006
DO  - 10.1016/j.tics.2019.02.006
T2  - Trends in Cognitive Sciences
JF  - Trends in Cognitive Sciences
SP  - 408
EP  - 422
VL  - 23
IS  - 5
PB  - Elsevier
N2  - Deep reinforcement learning (RL) methods have driven impressive advances in artificial intelligence in recent years, exceeding human performance in domains ranging from Atari to Go to no-limit poker. This progress has drawn the attention of cognitive scientists interested in understanding human learning. However, the concern has been raised that deep RL may be too sample-inefficient ? that is, it may simply be too slow ? to provide a plausible model of how humans learn. In the present review, we counter this critique by describing recently developed techniques that allow deep RL to operate more nimbly, solving problems much more quickly than previous methods. Although these techniques were developed in an AI context, we propose that they may have rich implications for psychology and neuroscience. A key insight, arising from these AI methods, concerns the fundamental connection between fast RL and slower, more incremental forms of learning.
AB  - Deep reinforcement learning (RL) methods have driven impressive advances in artificial intelligence in recent years, exceeding human performance in domains ranging from Atari to Go to no-limit poker. This progress has drawn the attention of cognitive scientists interested in understanding human learning. However, the concern has been raised that deep RL may be too sample-inefficient ? that is, it may simply be too slow ? to provide a plausible model of how humans learn. In the present review, we counter this critique by describing recently developed techniques that allow deep RL to operate more nimbly, solving problems much more quickly than previous methods. Although these techniques were developed in an AI context, we propose that they may have rich implications for psychology and neuroscience. A key insight, arising from these AI methods, concerns the fundamental connection between fast RL and slower, more incremental forms of learning.
SN  - 1364-6613
M3  - doi: 10.1016/j.tics.2019.02.006
UR  - https://doi.org/10.1016/j.tics.2019.02.006
Y2  - 2019/10/17
ER  - 
